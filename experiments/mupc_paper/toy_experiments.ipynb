{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy experiments\n",
    "\n",
    "## Main Contents\n",
    "- ðŸ”ï¸ [Inference landscape geometry of 1-MLPs](#Inference-landscape-geometry-of-1-MLPs)\n",
    "- ðŸ”ï¸ [Inference landscape geometry of 2-MLPs](#Inference-landscape-geometry-of-2-MLPs)\n",
    "- ðŸŽ¢ [Inference dynamics of 2-MLPs](#Inference-dynamics-of-2-MLPs)\n",
    "- ðŸ”ï¸ [Inference landscape slices of deep & wide MLPs](#Inference-landscape-slices-of-deep-&-wide-MLPs)\n",
    "- ðŸŽ¢ [Inference and learning dynamics of deep chains](#Inference-and-learning-dynamics-of-deep-chains)\n",
    "- ðŸŽ¢ [Training with $z^*$](#Training-with-$z^*$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install kaleido==0.2.1\n",
    "!pip install plotly==5.24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.random as jr\n",
    "import jax.numpy as jnp\n",
    "from jax import value_and_grad\n",
    "\n",
    "import jpc\n",
    "import equinox as eqx\n",
    "import optax\n",
    "from diffrax import (\n",
    "    Euler, \n",
    "    Heun, \n",
    "    Dopri5, \n",
    "    ConstantStepSize,\n",
    "    PIDController\n",
    ")\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.colors as pc\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')  # ignore warnings\n",
    "os.environ[\"BROWSER_PATH\"] = \"/home/myhome/chrome-headless-shell/linux-132.0.6834.83/chrome-headless-shell-linux64/chrome-headless-shell\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gaussian_dataset(key, mean, std, batch_size):\n",
    "    x = mean + std * jr.normal(key, (batch_size, 1))\n",
    "    y = x\n",
    "    return (x, y)\n",
    "\n",
    "\n",
    "def init_weight(network, idx, value):\n",
    "    where = lambda l: l[idx][1].weight\n",
    "    new_network = eqx.tree_at(where, network, jnp.array([value]))\n",
    "    return new_network\n",
    "\n",
    "\n",
    "def get_network_weights(network):\n",
    "    weights = [network[l][1].weight for l in range(len(network))]\n",
    "    return weights\n",
    "    \n",
    "\n",
    "def slice_energy_1D(network, zs, x, y):\n",
    "    w1 = network[0][1].weight\n",
    "    w2 = network[1][1].weight\n",
    "    \n",
    "    energy_slice = []\n",
    "    for z in zs:\n",
    "        energy = jpc.pc_energy_fn(\n",
    "            params=(network, None),\n",
    "            activities=[z, z],\n",
    "            y=y,\n",
    "            x=x\n",
    "        )\n",
    "        energy_slice.append(energy)\n",
    "    \n",
    "    z0 = w1*x\n",
    "    energy0 = jpc.pc_energy_fn(\n",
    "        params=(network, None),\n",
    "        activities=[z0, w2*zs],\n",
    "        y=y,\n",
    "        x=x\n",
    "    )\n",
    "    z_star = (w1*x + w2*y) / (1+w2**2)\n",
    "    energy_star = jpc.pc_energy_fn(\n",
    "        params=(network, None),\n",
    "        activities=[z_star, w2*z_star],\n",
    "        y=y,\n",
    "        x=x\n",
    "    )\n",
    "    return (\n",
    "        energy_slice, \n",
    "        z0.mean(), \n",
    "        energy0, \n",
    "        z_star.mean(), \n",
    "        energy_star\n",
    "    )\n",
    "\n",
    "\n",
    "def slice_energy_2D(network, skip_model, zs, x, y, param_type):\n",
    "    sampling_resolution = zs[0].shape[0]\n",
    "    use_skips = False if skip_model is None else True\n",
    "    \n",
    "    energy_mesh = jnp.zeros((sampling_resolution, sampling_resolution))\n",
    "    for k, z1 in enumerate(zs[0]):\n",
    "        for j, z2 in enumerate(zs[1]):\n",
    "            energy = jpc.pc_energy_fn(\n",
    "                (network, skip_model),\n",
    "                [z1, z2, z2],\n",
    "                y,\n",
    "                x=x,\n",
    "                param_type=param_type\n",
    "            )\n",
    "            energy_mesh = energy_mesh.at[j, k].set(energy)\n",
    "            \n",
    "    zs_star = jpc.compute_linear_activity_solution(\n",
    "        network, \n",
    "        x, \n",
    "        y, \n",
    "        use_skips=use_skips, \n",
    "        param_type=param_type\n",
    "    )\n",
    "    energy_star = jpc.pc_energy_fn(\n",
    "        params=(network, skip_model),\n",
    "        activities=zs_star,\n",
    "        y=y,\n",
    "        x=x,\n",
    "        param_type=param_type\n",
    "    )\n",
    "    return (\n",
    "        energy_mesh, \n",
    "        [z.mean() for z in zs_star], \n",
    "        energy_star\n",
    "    )\n",
    "\n",
    "\n",
    "def unwrap_hessian_pytree(hessian_pytree, activities, keep_last_term=False):\n",
    "    batch_size = activities[0].shape[0]\n",
    "    if not keep_last_term:\n",
    "        activities = activities[:-1]\n",
    "        hessian_pytree = hessian_pytree[:-1]\n",
    "        \n",
    "    widths = [a.shape[1] for a in activities]\n",
    "    N = sum(widths)\n",
    "    hessian_matrix = np.zeros((N, N))\n",
    "    \n",
    "    start_row_idx = 0\n",
    "    for l, pytree_l in enumerate(hessian_pytree):\n",
    "\n",
    "        if not keep_last_term:\n",
    "            pytree_l = pytree_l[:-1]\n",
    "            \n",
    "        start_col_idx = 0\n",
    "        for k, pytree_k in enumerate(pytree_l):\n",
    "            block = pytree_k.reshape(\n",
    "                batch_size, batch_size, widths[l], widths[k]\n",
    "            ).sum(axis=(0, 1))\n",
    "            \n",
    "            hessian_matrix[\n",
    "                start_row_idx:start_row_idx + widths[l], \n",
    "                start_col_idx:start_col_idx + widths[k]\n",
    "            ] = block\n",
    "  \n",
    "            start_col_idx += widths[k]\n",
    "    \n",
    "        start_row_idx += widths[l]\n",
    "\n",
    "    return hessian_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1D_energy_slices(network, weight_idx, zs, x, y, save_path, show_init=False):\n",
    "    base_energy_slice, base_z0, base_energy0, base_z_star, base_energy_star = slice_energy_1D(network, zs, x, y)\n",
    "    \n",
    "    larger_w_network = init_weight(network, weight_idx, 2)\n",
    "    smaller_w_network = init_weight(network, weight_idx, 0.1)\n",
    "    larger_w_energy_slice, larger_w_z0, larger_w_energy0, larger_w_z_star, larger_w_energy_star = slice_energy_1D(\n",
    "        larger_w_network, \n",
    "        zs, \n",
    "        x, \n",
    "        y\n",
    "    )\n",
    "    smaller_w_energy_slice, smaller_w_z0, smaller_w_energy0, smaller_w_z_star, smaller_w_energy_star = slice_energy_1D(\n",
    "        smaller_w_network, \n",
    "        zs, \n",
    "        x, \n",
    "        y\n",
    "    )\n",
    "    \n",
    "    z = zs[:, 0, 0]\n",
    "    colors = pc.sample_colorscale(\"Blues\", 5)\n",
    "    fig = go.Figure()\n",
    "    fig.add_traces(\n",
    "        go.Scatter(\n",
    "            x=z,\n",
    "            y=larger_w_energy_slice,\n",
    "            name=f\"$\\Large{{w_{weight_idx+1}>1}}$\",\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=3, color=colors[3])\n",
    "        )\n",
    "    )\n",
    "    fig.add_traces(\n",
    "        go.Scatter(\n",
    "            x=z,\n",
    "            y=base_energy_slice,\n",
    "            name=f\"$\\Large{{w_{weight_idx+1}=1}}$\",\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=3, color=colors[2])\n",
    "        )\n",
    "    )\n",
    "    fig.add_traces(\n",
    "        go.Scatter(\n",
    "            x=z,\n",
    "            y=smaller_w_energy_slice,\n",
    "            name=f\"$\\Large{{w_{weight_idx+1}<1}}$\",\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=3, color=colors[1])\n",
    "        )\n",
    "    )\n",
    "    for i, (z_star, energy_star) in enumerate(zip(\n",
    "        [base_z_star, larger_w_z_star, smaller_w_z_star],\n",
    "        [base_energy_star, larger_w_energy_star, smaller_w_energy_star]\n",
    "    )):\n",
    "        fig.add_traces(\n",
    "            go.Scatter(\n",
    "                x=[z_star],\n",
    "                y=[energy_star],\n",
    "                name=\"$\\Large{z^*}$\",\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    color=\"yellow\",\n",
    "                    size=10,\n",
    "                    line=dict(\n",
    "                        color='DarkSlateGrey',\n",
    "                        width=1\n",
    "                    ),\n",
    "                    symbol=\"star\"\n",
    "                ),\n",
    "                showlegend=True if i == 0 else False\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    if show_init:\n",
    "        for i, (z0, energy0) in enumerate(zip(\n",
    "            [base_z0, larger_w_z0, smaller_w_z0], \n",
    "            [base_energy0, larger_w_energy0, smaller_w_energy0]\n",
    "        )):\n",
    "            fig.add_traces(\n",
    "                go.Scatter(\n",
    "                    x=[z0],\n",
    "                    y=[energy0],\n",
    "                    name=\"$\\Large{z_0}$\",\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(\n",
    "                        color=\"black\",\n",
    "                        size=10,\n",
    "                        symbol=\"circle-open\"\n",
    "                    ),\n",
    "                    showlegend=True if i == 0 else False\n",
    "                )\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=350,\n",
    "        width=600,\n",
    "        xaxis=dict(title=\"$\\LARGE{z}$\"),\n",
    "        yaxis=dict(title=\"$\\LARGE{\\mathcal{F}}$\"),\n",
    "        font=dict(size=16),\n",
    "        margin=dict(r=130)\n",
    "    )\n",
    "    fig.write_image(save_path)\n",
    "\n",
    "\n",
    "def plot_energy_contour_2mlp(\n",
    "        network, \n",
    "        skip_model,\n",
    "        zs, \n",
    "        x, \n",
    "        y, \n",
    "        param_type,\n",
    "        title, \n",
    "        save_path, \n",
    "        smooth_contours=True, \n",
    "        activity_updates=None\n",
    "):\n",
    "    energy_mesh, zs_star, energy_star = slice_energy_2D(\n",
    "        network=network, \n",
    "        skip_model=skip_model,\n",
    "        zs=zs, \n",
    "        x=x, \n",
    "        y=y,\n",
    "        param_type=param_type\n",
    "    )\n",
    "    z1, z2 = zs[0][:, 0, 0], zs[1][:, 0, 0]\n",
    "\n",
    "    colorscale, points_color = \"Viridis\", \"yellow\"\n",
    "    contours_coloring = \"heatmap\" if smooth_contours else \"fill\"\n",
    "\n",
    "    # contour plot\n",
    "    contour = go.Contour(\n",
    "        z=energy_mesh,\n",
    "        x=z1,\n",
    "        y=z2,\n",
    "        colorscale=colorscale,\n",
    "        showscale=False,\n",
    "        contours_coloring=contours_coloring\n",
    "    )\n",
    "\n",
    "    # gradient vector field\n",
    "    # gradient_norm = jnp.sqrt(jnp.sum(gradient_field**2, axis=-1, keepdims=True))\n",
    "    # gradient_norm = jnp.where(gradient_norm > 0, gradient_norm, 1.0)\n",
    "    # gradient_field_normalized = gradient_field / gradient_norm\n",
    "    # z1_mesh, z2_mesh = jnp.meshgrid(z1, z2)\n",
    "    # quiver = ff.create_quiver(\n",
    "    #     x=z1_mesh,\n",
    "    #     y=z2_mesh,\n",
    "    #     u=gradient_field_scaled[:, :, 0],\n",
    "    #     v=gradient_field_scaled[:, :, 1],\n",
    "    #     marker_color=\"rgb(255, 255, 51)\",\n",
    "    #     opacity=0.9,\n",
    "    #     scale=0.1,\n",
    "    #     line_width=0.8,\n",
    "    #     showlegend=False\n",
    "    # )\n",
    "    fig = go.Figure(data=[contour]) #, quiver.data[0]])\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[zs_star[0]],\n",
    "            y=[zs_star[1]],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                color=points_color,\n",
    "                size=8,\n",
    "                line=dict(\n",
    "                    color=\"white\",\n",
    "                    width=1\n",
    "                ),\n",
    "                symbol=\"circle\"\n",
    "            ),\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "    z_star_displacement = 0.4 if activity_updates is None else 0.2\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[zs_star[0]+z_star_displacement], \n",
    "            y=[zs_star[1]+z_star_displacement],  \n",
    "            text=[\"$\\Large{z^*}$\"],  \n",
    "            mode=\"text\", \n",
    "            textfont=dict(size=20, color=points_color),  \n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # colorbar\n",
    "    max_energy, min_energy = float(energy_mesh.max()), float(energy_mesh.min())\n",
    "    colorbar_trace = go.Scatter(\n",
    "        x=[None],\n",
    "        y=[None],\n",
    "        mode=\"markers\",\n",
    "        showlegend=False,\n",
    "        marker=dict(\n",
    "            colorscale=colorscale,\n",
    "            showscale=True,\n",
    "            cmin=min_energy,\n",
    "            cmax=max_energy,\n",
    "            colorbar=dict(\n",
    "                title=\"$\\LARGE{\\mathcal{F}}$\",\n",
    "                len=0.5,\n",
    "                title_side=\"right\",\n",
    "                tickfont=dict(size=16),\n",
    "                tickvals=[min_energy, max_energy],\n",
    "                ticktext=[\"Low\", \"High\"]\n",
    "            )\n",
    "        ),\n",
    "        hoverinfo=\"none\"\n",
    "    )\n",
    "    fig.add_trace(colorbar_trace)\n",
    "\n",
    "    if activity_updates is not None:\n",
    "        fig.add_traces(\n",
    "            go.Scatter(\n",
    "                x=activity_updates[0],\n",
    "                y=activity_updates[1],\n",
    "                mode=\"lines+markers\",\n",
    "                line=dict(\n",
    "                    color=points_color,\n",
    "                    width=2\n",
    "                ),\n",
    "                marker=dict(\n",
    "                    size=4,\n",
    "                    color=points_color\n",
    "                ),\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    fig.update_layout(\n",
    "        xaxis=dict(title=\"$\\Large{z_1}$\", nticks=5),\n",
    "        yaxis=dict(title=\"$\\Large{z_2}$\", nticks=5),\n",
    "        font=dict(size=16),\n",
    "        plot_bgcolor=\"white\",\n",
    "        width=500, \n",
    "        height=400,\n",
    "        margin=dict(\n",
    "            r=100, \n",
    "            b=100,  # 50 \n",
    "            l=50, \n",
    "            t=80\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if title is not None:\n",
    "        fig.update_layout(\n",
    "            title=dict(\n",
    "                text=title,\n",
    "                y=0.85,\n",
    "                x=0.25 if \",\" not in title else 0.18,\n",
    "                xanchor=\"left\",\n",
    "                yanchor=\"top\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    fig.write_image(save_path)\n",
    "\n",
    "\n",
    "def plot_energy_surface_2mlp(\n",
    "        network,\n",
    "        skip_model,\n",
    "        zs,\n",
    "        x,\n",
    "        y,\n",
    "        param_type,\n",
    "        save_path\n",
    "    ):\n",
    "    energy_mesh, zs_star, energy_star = slice_energy_2D(\n",
    "        network=network, \n",
    "        skip_model=skip_model,\n",
    "        zs=zs, \n",
    "        x=x, \n",
    "        y=y,\n",
    "        param_type=param_type\n",
    "    )\n",
    "    z1, z2 = zs[0][:, 0, 0], zs[1][:, 0, 0]\n",
    "    \n",
    "    colorscale = \"Viridis\"\n",
    "    fig = go.Figure(\n",
    "        data=go.Surface(\n",
    "            z=energy_mesh,\n",
    "            x=z1,\n",
    "            y=z2,\n",
    "            colorscale=colorscale,\n",
    "        )\n",
    "    )\n",
    "    fig.update_traces(\n",
    "        contours_z=dict(\n",
    "            show=True,\n",
    "            usecolormap=True,\n",
    "            highlightcolor=\"limegreen\",\n",
    "            project_z=True\n",
    "        ),\n",
    "        showscale=False\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(\n",
    "                title=\"\",\n",
    "                autorange=\"reversed\",\n",
    "                showticklabels=False\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title=\"\",\n",
    "                autorange=\"reversed\",\n",
    "                showticklabels=False\n",
    "            ),\n",
    "            zaxis=dict(\n",
    "                title=\"\",\n",
    "                showticklabels=False\n",
    "            )\n",
    "        ),\n",
    "        scene_camera=dict(\n",
    "            center=dict(x=0.05, y=0.1, z=0),\n",
    "            eye=dict(x=0.75, y=1.8, z=1.25)\n",
    "        ),\n",
    "        font=dict(size=16),\n",
    "        height=600,\n",
    "        width=700,\n",
    "        scene_aspectmode=\"cube\"\n",
    "    )\n",
    "    fig.write_image(save_path)\n",
    "\n",
    "\n",
    "def plot_energy_surface_slice(energy_mesh, activities, save_path, showbackground=True):\n",
    "    energy_max, energy_min = energy_mesh.max(), energy_mesh.min()\n",
    "    min_max_diff = energy_max - energy_min\n",
    "    showscale = True if showbackground else False\n",
    "    fig = go.Figure(\n",
    "        data=go.Surface(\n",
    "            z=energy_mesh,\n",
    "            x=activities[0],\n",
    "            y=activities[1],\n",
    "            colorscale=\"Viridis\",\n",
    "            showscale=showscale,\n",
    "            colorbar=dict(\n",
    "                title=f\"$\\LARGE{{\\mathcal{{F}}}}$\",\n",
    "                x=0.85,\n",
    "                y=0.57,\n",
    "                len=0.3,\n",
    "                titleside=\"right\",\n",
    "                tickfont=dict(size=16),\n",
    "                tickvals=[energy_min, energy_max],\n",
    "                ticktext=[\"Low\" if min_max_diff > 0.1 else \"\", \"High\" if min_max_diff > 0.1 else \"\"]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    if showbackground:\n",
    "        fig.update_traces(\n",
    "            contours_z=dict(\n",
    "                show=True,\n",
    "                usecolormap=True,\n",
    "                highlightcolor=\"limegreen\",\n",
    "                project_z=True,\n",
    "            )\n",
    "        )\n",
    "    fig.update_layout(\n",
    "        scene=dict(zaxis=(dict(\n",
    "            title=\"\",\n",
    "            showticklabels=False\n",
    "        ))),\n",
    "        font=dict(size=16),\n",
    "        height=600,\n",
    "        width=700,\n",
    "        margin=dict(r=30, b=10, l=0, t=40),\n",
    "        scene_aspectmode=\"cube\"\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(\n",
    "                title=\"\",\n",
    "                autorange=\"reversed\",\n",
    "                showticklabels=False,\n",
    "                showbackground=showbackground\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title=\"\",\n",
    "                autorange=\"reversed\",\n",
    "                showticklabels=False,\n",
    "                showbackground=showbackground\n",
    "            ),\n",
    "            zaxis=dict(\n",
    "                showbackground=showbackground\n",
    "            )\n",
    "        ),\n",
    "        scene_camera=dict(\n",
    "            center=dict(x=0.05, y=0.2, z=0),\n",
    "            eye=dict(x=1.4, y=1.4, z=1.25)\n",
    "        )\n",
    "    )\n",
    "    fig.write_image(save_path)\n",
    "\n",
    "\n",
    "def plot_energy_contour_slice(\n",
    "        energy_mesh,\n",
    "        activities,\n",
    "        plot_solution,\n",
    "        save_path,\n",
    "        smooth_contours=True\n",
    "):\n",
    "    colorscale, points_color = \"Viridis\", \"yellow\"\n",
    "    contours_coloring = \"heatmap\" if smooth_contours else \"fill\"\n",
    "\n",
    "    # contour plot\n",
    "    contour = go.Contour(\n",
    "        z=energy_mesh,\n",
    "        x=activities[0],\n",
    "        y=activities[1],\n",
    "        colorscale=colorscale,\n",
    "        showscale=False,\n",
    "        contours_coloring=contours_coloring\n",
    "    )\n",
    "    fig = go.Figure(data=[contour])\n",
    "    if plot_solution:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[0],\n",
    "                y=[0],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    color=points_color,\n",
    "                    size=8,\n",
    "                    line=dict(\n",
    "                        color=\"white\",\n",
    "                        width=1\n",
    "                    ),\n",
    "                    symbol=\"circle\"\n",
    "                ),\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[0 + 0.3],\n",
    "                y=[0 + 0.3],\n",
    "                text=[\"$\\Large{z^*}$\"],\n",
    "                mode=\"text\",\n",
    "                textfont=dict(size=20, color=points_color),\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # colorbar\n",
    "    max_energy, min_energy = float(energy_mesh.max()), float(energy_mesh.min())\n",
    "    colorbar_trace = go.Scatter(\n",
    "        x=[None],\n",
    "        y=[None],\n",
    "        mode=\"markers\",\n",
    "        showlegend=False,\n",
    "        marker=dict(\n",
    "            colorscale=colorscale,\n",
    "            showscale=True,\n",
    "            cmin=min_energy,\n",
    "            cmax=max_energy,\n",
    "            colorbar=dict(\n",
    "                title=\"$\\LARGE{\\mathcal{F}}$\",\n",
    "                len=0.5,\n",
    "                title_side=\"right\",\n",
    "                tickfont=dict(size=16),\n",
    "                tickvals=[min_energy, max_energy],\n",
    "                ticktext=[\"Low\", \"High\"]\n",
    "            )\n",
    "        ),\n",
    "        hoverinfo=\"none\"\n",
    "    )\n",
    "    fig.add_trace(colorbar_trace)\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(title=\"$\\Large{\\hat{\\mathbf{v}}_{min}}$\", nticks=5),\n",
    "        yaxis=dict(title=\"$\\Large{\\hat{\\mathbf{v}}_{max}}$\", nticks=5),\n",
    "        font=dict(size=16),\n",
    "        plot_bgcolor=\"white\",\n",
    "        width=500,\n",
    "        height=400,\n",
    "        margin=dict(\n",
    "            r=100,\n",
    "            b=100,\n",
    "            l=50,\n",
    "            t=80\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.write_image(save_path)\n",
    "\n",
    "\n",
    "def visualise_energy_slice(\n",
    "        model,\n",
    "        skip_model,\n",
    "        x,\n",
    "        y,\n",
    "        use_skips,\n",
    "        param_type,\n",
    "        activity_decay,\n",
    "        domain,\n",
    "        sampling_resolution,\n",
    "        hessian_eigenvecs,\n",
    "        save_path,\n",
    "        plot_solution,\n",
    "        showbackground=True\n",
    "):\n",
    "    scaling_factors = [\n",
    "        np.linspace(\n",
    "            -domain, domain, sampling_resolution\n",
    "        ) for _ in range(2)\n",
    "    ]\n",
    "    energy_mesh = np.zeros((sampling_resolution, sampling_resolution))\n",
    "    for j, a in enumerate(scaling_factors[0]):\n",
    "        for i, b in enumerate(scaling_factors[1]):\n",
    "            # get vector of activities' linear solution\n",
    "            all_zs_star = jpc.compute_linear_activity_solution(\n",
    "                network=model,\n",
    "                x=x,\n",
    "                y=y,\n",
    "                use_skips=use_skips,\n",
    "                param_type=param_type,\n",
    "                activity_decay=activity_decay\n",
    "            )\n",
    "            zs_star = all_zs_star[:-1]\n",
    "            z_widths = [z.shape[1] for z in zs_star]\n",
    "\n",
    "            # flatten for perturbation\n",
    "            z_vec = np.hstack(zs_star)\n",
    "\n",
    "            # perturb along 2 main hessian directions\n",
    "            perturbed_z_vec = z_vec + (a * hessian_eigenvecs[0]) + (b * hessian_eigenvecs[-1])\n",
    "\n",
    "            # reshape perturbed vector into layers\n",
    "            split_indices = np.cumsum(z_widths)[:-1]\n",
    "            perturbed_activities = np.hsplit(perturbed_z_vec, split_indices)\n",
    "\n",
    "            energy = jpc.pc_energy_fn(\n",
    "                (model, skip_model),\n",
    "                perturbed_activities + [all_zs_star[-1]],\n",
    "                y,\n",
    "                x=x,\n",
    "                param_type=param_type,\n",
    "                activity_decay=activity_decay\n",
    "            )\n",
    "            energy_mesh[i, j] = energy\n",
    "\n",
    "    plot_energy_surface_slice(\n",
    "        energy_mesh,\n",
    "        scaling_factors,\n",
    "        f\"{save_path}_surface.pdf\",\n",
    "        showbackground=showbackground\n",
    "    )\n",
    "    plot_energy_contour_slice(\n",
    "        energy_mesh,\n",
    "        scaling_factors,\n",
    "        plot_solution,\n",
    "        f\"{save_path}_contour.pdf\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_MEAN, DATA_STD = 1., 0.1\n",
    "BATCH_SIZE = 64\n",
    "ACT_FNS = [\"linear\", \"tanh\", \"relu\"]\n",
    "SAMPLING_RESOLUTION = 30\n",
    "\n",
    "SAVE_DIR = \"toy_results\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Inference landscape geometry of 1-MLPs\n",
    "This code snippet visualises the activity or inference landscape of scalar predictive coding networks with 1 hidden unit (1-MLPs), i.e. $\\mathcal{F}(z) = (z - w_1x)^2 + (y-w_2z)^2$. Since the landscape is convex (at least in the linear case), it is completely characterised by the activity Hessian, which for 1-MLPs is given by $H_{\\mathbf{z}} \\coloneqq \\partial^2 \\mathcal{F}/ \\partial z^2 = 1 + w_2^2$. The plots verify this by showing that only perturbations of $w_2$, and not $w_1$, change the curvature of the landscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp1_save_dir = f\"{SAVE_DIR}/1mlps\"\n",
    "os.makedirs(mlp1_save_dir, exist_ok=True)\n",
    "\n",
    "key = jr.PRNGKey(54829)\n",
    "keys = jr.split(key, 2)\n",
    "\n",
    "X, Y = make_gaussian_dataset(keys[0], DATA_MEAN, DATA_STD, BATCH_SIZE)\n",
    "DOMAIN = 3\n",
    "Zs = jnp.tile(\n",
    "    jnp.linspace(-DOMAIN, DOMAIN, SAMPLING_RESOLUTION), \n",
    "    (BATCH_SIZE, 1)\n",
    ").T[:, :, jnp.newaxis]\n",
    "\n",
    "for act_fn in ACT_FNS:\n",
    "    print(f\"act fn: {act_fn}\")\n",
    "    network = jpc.make_mlp(\n",
    "        key=keys[1],\n",
    "        input_dim=1,\n",
    "        width=1,\n",
    "        depth=2,\n",
    "        output_dim=1,\n",
    "        act_fn=act_fn,\n",
    "        use_bias=False\n",
    "    )\n",
    "\n",
    "    # set all the weights to 1 for simplicity\n",
    "    where1, where2 = lambda l: l[0][1].weight, lambda l: l[1][1].weight\n",
    "    network = eqx.tree_at(where1, network, jnp.array([1]))\n",
    "    network = eqx.tree_at(where2, network, jnp.array([1]))\n",
    "    \n",
    "    for i in range(2):\n",
    "        plot_1D_energy_slices(network, i, Zs, X, Y, f\"{mlp1_save_dir}/{act_fn}_w{i+1}_energy_slices.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Inference landscape geometry of 2-MLPs\n",
    "This extends the previous analysis by visualising the inference landscape of scalar predictive coding networks with 2 hidden units (2-MLPs), i.e. $\\mathcal{F}(\\mathbf{z}) = (z_1 - a_1 w_1x)^2 + (z_2 - a_2 w_2z_1)^2 + (y - a_3 w_3z_2)^2$. The (2D) landscape is visualised both as a contour and as a surface plot. The results confirm the 1-MLP analysis.\n",
    "\n",
    "We also compare the standard parameterisation (SP) given by $a_1 = a_2 = a_3 = 1$ with what we call \"$\\mu$PC\" where $a_2 = 3$. We observe no notable differences, which is expected given the small depth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2_save_dir = f\"{SAVE_DIR}/2mlps\"\n",
    "os.makedirs(mlp2_save_dir, exist_ok=True)\n",
    "\n",
    "key = jr.PRNGKey(4328704)\n",
    "keys = jr.split(key, 2)\n",
    "\n",
    "X, Y = make_gaussian_dataset(\n",
    "    keys[0], \n",
    "    DATA_MEAN, \n",
    "    DATA_STD, \n",
    "    BATCH_SIZE\n",
    ")\n",
    "DOMAIN = 2\n",
    "Zs = [\n",
    "    jnp.tile(\n",
    "        jnp.linspace(-DOMAIN, DOMAIN, SAMPLING_RESOLUTION), \n",
    "        (BATCH_SIZE, 1)\n",
    "    ).T[:, :, jnp.newaxis] for i in range(2)\n",
    "]\n",
    "\n",
    "PARAM_TYPES = [\"sp\", \"mupc\"]\n",
    "for param_type in PARAM_TYPES:\n",
    "    print(f\"\\nparam type: {param_type}\\n\")\n",
    "    \n",
    "    for act_fn in ACT_FNS:\n",
    "        print(f\"\\tact fn: {act_fn}\")\n",
    "        save_dir = f\"{mlp2_save_dir}/{param_type}/{act_fn}\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        network = jpc.make_mlp(\n",
    "            key=keys[1],\n",
    "            input_dim=1,\n",
    "            width=1,\n",
    "            depth=3,\n",
    "            output_dim=1,\n",
    "            act_fn=act_fn,\n",
    "            use_bias=False,\n",
    "            param_type=param_type\n",
    "        )\n",
    "        skip_model = jpc.make_skip_model(3) if param_type == \"mupc\" else None\n",
    "    \n",
    "        # set all the weights to 1 for simplicity\n",
    "        where1, where2, where3 = lambda l: l[0][1].weight, lambda l: l[1][1].weight, lambda l: l[2][1].weight\n",
    "        network = eqx.tree_at(where1, network, jnp.array([[1]]))\n",
    "        network = eqx.tree_at(where2, network, jnp.array([[1]]))\n",
    "        network = eqx.tree_at(where3, network, jnp.array([[1]]))\n",
    "    \n",
    "        # create networks with imbalanced weights\n",
    "        larger_w2_network = init_weight(network, 1, 3)\n",
    "        larger_w3_network = init_weight(network, 2, 3)\n",
    "    \n",
    "        # landscape contour plots\n",
    "        plot_energy_contour_2mlp(\n",
    "            network, \n",
    "            skip_model,\n",
    "            Zs, \n",
    "            X, \n",
    "            Y, \n",
    "            param_type,\n",
    "            title=\"$\\Large{w_3=w_2=w_1=1}$\", \n",
    "            save_path=f\"{save_dir}/energy_contour.pdf\"\n",
    "        )\n",
    "        plot_energy_contour_2mlp(\n",
    "            larger_w2_network,\n",
    "            skip_model,\n",
    "            Zs, \n",
    "            X, \n",
    "            Y, \n",
    "            param_type,\n",
    "            title=\"$\\Large{w_3=1, w_2=3, w_1=1}$\", \n",
    "            save_path=f\"{save_dir}/energy_contour_large_w2.pdf\"\n",
    "        )\n",
    "        plot_energy_contour_2mlp(\n",
    "            larger_w3_network, \n",
    "            skip_model,\n",
    "            Zs, \n",
    "            X, \n",
    "            Y, \n",
    "            param_type,\n",
    "            title=\"$\\Large{w_3=3, w_2=1, w_1=1}$\", \n",
    "            save_path=f\"{save_dir}/energy_contour_large_w3.pdf\"\n",
    "        )\n",
    "    \n",
    "        # landscape surface plots\n",
    "        plot_energy_surface_2mlp(\n",
    "            network,\n",
    "            skip_model,\n",
    "            Zs,\n",
    "            X,\n",
    "            Y,\n",
    "            param_type,\n",
    "            save_path=f\"{save_dir}/energy_surface.pdf\"\n",
    "        )\n",
    "        plot_energy_surface_2mlp(\n",
    "            larger_w2_network,\n",
    "            skip_model,\n",
    "            Zs,\n",
    "            X,\n",
    "            Y,\n",
    "            param_type,\n",
    "            save_path=f\"{save_dir}/energy_surface_large_w2.pdf\"\n",
    "        )\n",
    "        plot_energy_surface_2mlp(\n",
    "            larger_w3_network,\n",
    "            skip_model,\n",
    "            Zs,\n",
    "            X,\n",
    "            Y,\n",
    "            param_type,\n",
    "            save_path=f\"{save_dir}/energy_surface_large_w3.pdf\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Inference dynamics of 2-MLPs\n",
    "This extends the previous analysis of 2-MLPs by also visualising the minimisation $\\min_z \\mathcal{F}$ with different optimisers (e.g. gradient flow vs gradient descent vs Adam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2_save_dir = f\"{SAVE_DIR}/2mlps\"\n",
    "os.makedirs(mlp2_save_dir, exist_ok=True)\n",
    "\n",
    "key = jr.PRNGKey(10473)\n",
    "keys = jr.split(key, 2)\n",
    "\n",
    "SKIP_MODEL = None\n",
    "PARAM_TYPE = \"sp\"\n",
    "MAX_T1 = 50\n",
    "\n",
    "X, Y = make_gaussian_dataset(\n",
    "    keys[0], \n",
    "    DATA_MEAN, \n",
    "    DATA_STD, \n",
    "    BATCH_SIZE\n",
    ")\n",
    "DOMAIN = 2\n",
    "Zs = [\n",
    "    jnp.tile(\n",
    "        jnp.linspace(-DOMAIN, DOMAIN, SAMPLING_RESOLUTION), \n",
    "        (BATCH_SIZE, 1)\n",
    "    ).T[:, :, jnp.newaxis] for i in range(2)\n",
    "]\n",
    "\n",
    "ODE_SOLVERS = {\n",
    "    \"Euler\": Euler(), \n",
    "    \"Heun\": Heun(), \n",
    "    \"Dopri5\": Dopri5(), \n",
    "}\n",
    "\n",
    "for act_fn in ACT_FNS:\n",
    "    print(f\"act fn: {act_fn}\")\n",
    "    save_dir = f\"{mlp2_save_dir}/{PARAM_TYPE}/{act_fn}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    network = jpc.make_mlp(\n",
    "        key=keys[1],\n",
    "        input_dim=1,\n",
    "        width=1,\n",
    "        depth=3,\n",
    "        output_dim=1,\n",
    "        act_fn=act_fn,\n",
    "        use_bias=False,\n",
    "        param_type=PARAM_TYPE\n",
    "    )\n",
    "    where1, where2, where3 = lambda l: l[0][1].weight, lambda l: l[1][1].weight, lambda l: l[2][1].weight\n",
    "    network = eqx.tree_at(where1, network, jnp.array([[1 if act_fn == \"relu\" else -1]]))\n",
    "    network = eqx.tree_at(where2, network, jnp.array([[2]]))\n",
    "    network = eqx.tree_at(where3, network, jnp.array([[10]]))\n",
    "\n",
    "    w1 = network[0][1].weight\n",
    "    w2 = network[1][1].weight\n",
    "    w3 = network[2][1].weight\n",
    "    \n",
    "    weights = get_network_weights(network)\n",
    "    activity_hessian = jpc.compute_linear_activity_hessian(weights)\n",
    "    cond_num = jnp.linalg.cond(activity_hessian)\n",
    "    \n",
    "    optim = optax.adam(1e-3)\n",
    "    opt_state = optim.init(\n",
    "        (eqx.filter(network, eqx.is_array), SKIP_MODEL)\n",
    "    )\n",
    "\n",
    "    #################### ODE solvers ####################\n",
    "    for solver_id, solver in ODE_SOLVERS.items():\n",
    "        dt = 5e-1 if solver_id == \"Euler\" else 5e-1\n",
    "        stepsize_controller = ConstantStepSize() if (\n",
    "            solver_id == \"Euler\" \n",
    "        ) else PIDController(rtol=1e-3, atol=1e-3)\n",
    "        \n",
    "        result = jpc.make_pc_step(\n",
    "            network,\n",
    "            optim,\n",
    "            opt_state,\n",
    "            output=Y,\n",
    "            input=X,\n",
    "            ode_solver=solver,\n",
    "            max_t1=MAX_T1,\n",
    "            dt=dt,\n",
    "            stepsize_controller=stepsize_controller,\n",
    "            record_activities=True\n",
    "        )\n",
    "        t_max, activities = result[\"t_max\"], result[\"activities\"]    \n",
    "        plot_energy_contour_2mlp(\n",
    "            network, \n",
    "            SKIP_MODEL,\n",
    "            Zs, \n",
    "            X, \n",
    "            Y,\n",
    "            PARAM_TYPE,\n",
    "            title=None, \n",
    "            save_path=f\"{save_dir}/{solver_id}_dynamics_dt_{dt}_t1_{MAX_T1}.pdf\",\n",
    "            activity_updates=[\n",
    "                activities[0][:t_max+1].mean(axis=(-2, -1)), \n",
    "                activities[1][:t_max+1].mean(axis=(-2, -1))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    #################### GD ####################\n",
    "    activity_optim = optax.sgd(5e-1)\n",
    "    activities = jpc.init_activities_with_ffwd(\n",
    "        model=network,\n",
    "        input=X\n",
    "    )\n",
    "    activity_opt_state = activity_optim.init(activities)    \n",
    "    activity_updates = [[], []]\n",
    "    t_max = 100\n",
    "    for t in range(t_max):\n",
    "        energy, activity_grads = jpc.compute_activity_grad(\n",
    "            params=(network, SKIP_MODEL),\n",
    "            activities=activities,\n",
    "            y=Y,\n",
    "            x=X\n",
    "        )\n",
    "        updates, activity_opt_state = activity_optim.update(\n",
    "            updates=activity_grads,\n",
    "            state=activity_opt_state,\n",
    "            params=activities\n",
    "        )\n",
    "        activities = eqx.apply_updates(\n",
    "            model=activities,\n",
    "            updates=updates\n",
    "        )\n",
    "        activity_updates[0].append(activities[0].mean())\n",
    "        activity_updates[1].append(activities[1].mean())\n",
    "    \n",
    "    plot_energy_contour_2mlp(\n",
    "        network, \n",
    "        SKIP_MODEL,\n",
    "        Zs, \n",
    "        X, \n",
    "        Y,\n",
    "        PARAM_TYPE,\n",
    "        title=None, \n",
    "        save_path=f\"{save_dir}/GD_dynamics_t_{t_max}.pdf\",\n",
    "        activity_updates=activity_updates\n",
    "    )\n",
    "    \n",
    "    #################### Adam ####################\n",
    "    activity_optim = optax.adam(5e-1)\n",
    "    activities = jpc.init_activities_with_ffwd(\n",
    "        model=network,\n",
    "        input=X\n",
    "    )\n",
    "    activity_opt_state = activity_optim.init(activities)    \n",
    "    activity_updates = [[], []]\n",
    "    t_max = 4\n",
    "    for t in range(t_max):\n",
    "        energy, activity_grads = jpc.compute_activity_grad(\n",
    "            params=(network, SKIP_MODEL),\n",
    "            activities=activities,\n",
    "            y=Y,\n",
    "            x=X\n",
    "        )\n",
    "        updates, activity_opt_state = activity_optim.update(\n",
    "            updates=activity_grads,\n",
    "            state=activity_opt_state,\n",
    "            params=activities\n",
    "        )\n",
    "        activities = eqx.apply_updates(\n",
    "            model=activities,\n",
    "            updates=updates\n",
    "        )\n",
    "        activity_updates[0].append(activities[0].mean())\n",
    "        activity_updates[1].append(activities[1].mean())\n",
    "    \n",
    "    plot_energy_contour_2mlp(\n",
    "        network, \n",
    "        SKIP_MODEL,\n",
    "        Zs, \n",
    "        X, \n",
    "        Y,\n",
    "        PARAM_TYPE,\n",
    "        title=None, \n",
    "        save_path=f\"{save_dir}/Adam_dynamics_t_{t_max}.pdf\",\n",
    "        activity_updates=activity_updates\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference landscape slices of deep & wide MLPs\n",
    "This plots slices of the energy for arbitrary MLPs at the linear inference solution along the biggest and smallest curvature directions, i.e. $\\mathcal{F}(z^* + \\alpha \\hat{v}_{\\text{min}} + \\beta \\hat{v}_{\\text{max}})$ where $\\hat{v}_{\\text{max}}$ and $\\hat{v}_{\\text{min}}$ are the maximum and minimum eigenvectors of the activity Hessian, respectively. For both linear and nonlinear networks, we find that: \n",
    "* the landscape always becomes more ill-conditioned with depth, and\n",
    "* skip connections greatly increase ill-conditionness at large depth, although more so for the standard (vs $\\mu$PC) parameterisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "width and depth: {'width': 128, 'depth': 16}\n",
      "\n",
      "\tparam type: sp\n",
      "\n",
      "\t\tuse_skips: False\n",
      "\n",
      "\t\t\tact fn: linear\n",
      "\n",
      "\t\t\t\tcondition number: 42.1188\n",
      "\n",
      "\t\t\tact fn: tanh\n",
      "\n",
      "\t\t\t\tcondition number: 41.9170\n",
      "\n",
      "\t\t\tact fn: relu\n",
      "\n",
      "\t\t\t\tcondition number: 15.7973\n",
      "\n",
      "\t\tuse_skips: True\n",
      "\n",
      "\t\t\tact fn: linear\n",
      "\n",
      "\t\t\t\tcondition number: 45765.4336\n",
      "\n",
      "\t\t\tact fn: tanh\n",
      "\n",
      "\t\t\t\tcondition number: 534.2700\n",
      "\n",
      "\t\t\tact fn: relu\n",
      "\n",
      "\t\t\t\tcondition number: 9763.3066\n",
      "\n",
      "\tparam type: mupc\n",
      "\n",
      "\t\tuse_skips: True\n",
      "\n",
      "\t\t\tact fn: linear\n",
      "\n",
      "\t\t\t\tcondition number: 1917.8442\n",
      "\n",
      "\t\t\tact fn: tanh\n",
      "\n",
      "\t\t\t\tcondition number: 1343.7063\n",
      "\n",
      "\t\t\tact fn: relu\n",
      "\n",
      "\t\t\t\tcondition number: 1345.4940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_landscape_save_dir = f\"{SAVE_DIR}/mlps/landscape_slices\"\n",
    "os.makedirs(mlp_landscape_save_dir, exist_ok=True)\n",
    "\n",
    "key = jr.PRNGKey(19235)\n",
    "keys = jr.split(key, 2)\n",
    "\n",
    "DOMAIN = 2\n",
    "X, Y = make_gaussian_dataset(keys[0], DATA_MEAN, DATA_STD, 1)\n",
    "\n",
    "WIDTH_DEPTH_COMBOS = [\n",
    "    {\"width\": 128, \"depth\": 16},\n",
    "    #{\"width\": 2, \"depth\": 3}\n",
    "]\n",
    "PARAM_TYPES = [\"sp\", \"mupc\"]\n",
    "\n",
    "for width_depth in WIDTH_DEPTH_COMBOS:\n",
    "    print(f\"\\nwidth and depth: {width_depth}\\n\")\n",
    "    width = width_depth[\"width\"]\n",
    "    depth = width_depth[\"depth\"]\n",
    "    \n",
    "    for param_type in PARAM_TYPES:\n",
    "        print(f\"\\tparam type: {param_type}\\n\")\n",
    "        \n",
    "        skip_uses = [False, True] if param_type == \"sp\" else [True]\n",
    "        for use_skips in skip_uses:\n",
    "            print(f\"\\t\\tuse_skips: {use_skips}\\n\")\n",
    "        \n",
    "            for act_fn in ACT_FNS:\n",
    "                print(f\"\\t\\t\\tact fn: {act_fn}\\n\")\n",
    "                \n",
    "                save_dir = os.path.join(\n",
    "                    mlp_landscape_save_dir,\n",
    "                    param_type,\n",
    "                    \"skips\" if use_skips else \"no_skips\",\n",
    "                    act_fn\n",
    "                )\n",
    "                os.makedirs(save_dir, exist_ok=True)\n",
    "            \n",
    "                network = jpc.make_mlp(\n",
    "                    keys[1], \n",
    "                    input_dim=1,\n",
    "                    width=width,\n",
    "                    depth=depth,\n",
    "                    output_dim=1,\n",
    "                    act_fn=act_fn, \n",
    "                    use_bias=False,\n",
    "                    param_type=param_type\n",
    "                )\n",
    "                skip_model = jpc.make_skip_model(depth) if use_skips else None\n",
    "                \n",
    "                activities = jpc.init_activities_with_ffwd(\n",
    "                    network, \n",
    "                    X, \n",
    "                    skip_model=skip_model,\n",
    "                    param_type=param_type\n",
    "                )\n",
    "                hessian_pytree = jax.hessian(jpc.pc_energy_fn, argnums=1)(\n",
    "                    (network, skip_model),\n",
    "                    activities,\n",
    "                    Y,\n",
    "                    x=X,\n",
    "                    param_type=param_type\n",
    "                )\n",
    "                num_H = unwrap_hessian_pytree(hessian_pytree, activities)\n",
    "                eigenvals, eigenvecs = jnp.linalg.eigh(num_H)\n",
    "                cond_num = np.abs(max(eigenvals))/np.abs(min(eigenvals))\n",
    "                print(f\"\\t\\t\\t\\tcondition number: {cond_num:.4f}\\n\")\n",
    "                \n",
    "                min_max_eigenvecs = [eigenvecs[:, 0], eigenvecs[:, -1]]\n",
    "                    \n",
    "                visualise_energy_slice(\n",
    "                    model=network, \n",
    "                    skip_model=skip_model, \n",
    "                    x=X, \n",
    "                    y=Y, \n",
    "                    use_skips=use_skips,\n",
    "                    param_type=\"sp\",\n",
    "                    activity_decay=False, \n",
    "                    domain=DOMAIN, \n",
    "                    sampling_resolution=SAMPLING_RESOLUTION, \n",
    "                    hessian_eigenvecs=min_max_eigenvecs, \n",
    "                    save_path=f\"{save_dir}/energy_slice_N_{width}_L_{depth}\", \n",
    "                    plot_solution=True if act_fn == \"linear\" else False,\n",
    "                    showbackground=False  # changed\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Inference & learning dynamics of deep chains\n",
    "The script below analyses the inference and learning dynamics of deep chains or scalar PCNs ($N=1$) for different parameterisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.tree_util import tree_map\n",
    "\n",
    "from utils import (\n",
    "    init_weights,    \n",
    "    compute_param_spectral_norms, \n",
    "    compute_hessian_eigens\n",
    ")\n",
    "from plotting import (\n",
    "    plot_loss,\n",
    "    plot_norms,\n",
    "    plot_energies,\n",
    "    plot_max_min_eigenvals,\n",
    "    plot_max_min_eigenvals_2_axes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activities(activities, save_path, theory_activities=None, log=False):\n",
    "    n_layers = activities.shape[1]\n",
    "    n_train_iters = activities.shape[0]\n",
    "    train_iters = [t for t in range(n_train_iters)]\n",
    "    layer_idxs = [1, \"1/4L\", \"1/2L\", \"3/4L\", \"L\"]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    if theory_activities is not None:\n",
    "        fig.add_traces(\n",
    "            go.Scatter(\n",
    "                x=[None],\n",
    "                y=[None],\n",
    "                mode=\"lines\",\n",
    "                line=dict(width=3, color=\"black\", dash=\"dash\"),\n",
    "                name=\"theory\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    colorscale = \"Reds\"\n",
    "    colors = pc.sample_colorscale(colorscale, n_layers + 2)[2:]\n",
    "    for i, color in enumerate(colors):\n",
    "        layer_idx = layer_idxs[i]\n",
    "\n",
    "        if n_train_iters == 1:\n",
    "            fig.add_hline(\n",
    "                y=activities[0, i],\n",
    "                name=f\"$\\ell = {{{layer_idx}}}$\",\n",
    "                line=dict(\n",
    "                    color=color,\n",
    "                    width=2\n",
    "                ),\n",
    "                showlegend=True\n",
    "            )\n",
    "        else:\n",
    "            fig.add_traces(\n",
    "                go.Scatter(\n",
    "                    x=train_iters,\n",
    "                    y=activities[:, i],\n",
    "                    name=f\"$\\ell = {{{layer_idx}}}$\",\n",
    "                    mode=\"lines\",\n",
    "                    line=dict(\n",
    "                        width=2,\n",
    "                        color=color\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        if theory_activities is not None:\n",
    "            fig.add_hline(\n",
    "                y=theory_activities[i],\n",
    "                line=dict(\n",
    "                    color=color,\n",
    "                    width=4,\n",
    "                    dash=\"dash\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=350,\n",
    "        width=525,\n",
    "        xaxis=dict(\n",
    "            title=\"Inference iteration\",\n",
    "            showticklabels=False\n",
    "        ),\n",
    "        yaxis=dict(title=\"$\\Large{z_\\ell}$\"),\n",
    "        font=dict(size=18),\n",
    "        margin=dict(r=140, l=100, b=90)\n",
    "    )\n",
    "    if log:\n",
    "        fig.update_layout(\n",
    "            yaxis=dict(\n",
    "                type=\"log\",\n",
    "                exponentformat=\"power\",\n",
    "                dtick=1\n",
    "            )\n",
    "        )\n",
    "    if n_train_iters > 1:\n",
    "        fig.update_layout(\n",
    "            xaxis=dict(\n",
    "                showticklabels=True,\n",
    "                tickvals=[0, int(train_iters[-1] / 2), train_iters[-1]],\n",
    "                ticktext=[0, int(train_iters[-1] / 2), train_iters[-1]]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    fig.write_image(save_path)\n",
    "\n",
    "\n",
    "def plot_2D_data(x, y, y_hat, save_path):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x[:, 0],\n",
    "            y=y[:, 0],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=8, color=\"#636EFA\"),\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x[:, 0],\n",
    "            y=y_hat[:, 0],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=8, color=\"#EF553B\"),\n",
    "            name=\"$\\hat{y}$\"\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        height=300,\n",
    "        width=400,\n",
    "        xaxis=dict(title=\"$\\Large{x}$\"),\n",
    "        yaxis=dict(title=\"$\\Large{y}$\"),\n",
    "        font=dict(size=16)\n",
    "    )\n",
    "    fig.write_image(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains_save_dir = f\"{SAVE_DIR}/deep_chains\"\n",
    "os.makedirs(chains_save_dir, exist_ok=True)\n",
    "\n",
    "key = jax.random.PRNGKey(23853)\n",
    "keys = jax.random.split(key, 3)\n",
    "\n",
    "DATA_MEAN, DATA_STD = 1, 1\n",
    "NOISE_STD = 0.5\n",
    "WIDTH = 1\n",
    "BATCH_SIZE = 64\n",
    "N_TRAIN_ITERS = 1000\n",
    "TEST_EVERY = 100\n",
    "\n",
    "N_HIDDENS = [64]#[2**i for i in range(3, 7)]\n",
    "PARAM_TYPES = [\"mupc\"]#, \"sp\"]\n",
    "ACTIVITY_INITS = [\"ffwd\"]#, \"ffwd\", \"random\"]\n",
    "\n",
    "for n_hidden in N_HIDDENS:\n",
    "    print(f\"\\nn_hidden = {n_hidden}\")\n",
    "    \n",
    "    for param_type in PARAM_TYPES:\n",
    "        print(f\"\\n\\tparam type: {param_type}\")\n",
    "        \n",
    "        param_lr = 1e-3 #if param_type == \"sp\" else 1e-1\n",
    "        skip_uses = [True] if param_type == \"sp\" else [True]  # NOTE: removed nonskip from sp for testing\n",
    "        \n",
    "        for use_skips in skip_uses:\n",
    "            print(f\"\\n\\t\\tuse_skips: {use_skips}\")\n",
    "\n",
    "            for activity_init in ACTIVITY_INITS:\n",
    "                print(f\"\\n\\t\\t\\tactivity init: {activity_init}\")\n",
    "\n",
    "                if activity_init == \"theory\":\n",
    "                    max_infer_iters = [0] \n",
    "                    activity_lrs = [1]\n",
    "                    act_fns = [\"linear\"]\n",
    "                else:  \n",
    "                    max_infer_iters = [1, n_hidden, n_hidden*2]\n",
    "                    activity_lrs = [1, 10, 50]\n",
    "                    act_fns = [\"linear\"] #, \"tanh\", \"relu\"]  # NOTE: removed for testing\n",
    "                    \n",
    "                for act_fn in act_fns:\n",
    "                    print(f\"\\n\\t\\t\\t\\tact fn: {act_fn}\")\n",
    "\n",
    "                    for activity_lr in activity_lrs:\n",
    "                        print(f\"\\n\\t\\t\\t\\t\\tactivity_lr: {activity_lr}\")\n",
    "            \n",
    "                        for n_infer_iters in max_infer_iters: \n",
    "                            print(f\"\\n\\t\\t\\t\\t\\t\\tn_infer_iters: {n_infer_iters}\\n\")\n",
    "\n",
    "                            save_dir = os.path.join(\n",
    "                                chains_save_dir,\n",
    "                                f\"noise_std_{NOISE_STD}\",\n",
    "                                f\"{n_hidden}_n_hidden\",\n",
    "                                param_type,\n",
    "                                \"skips\" if use_skips else \"no_skips\",\n",
    "                                f\"{activity_init}_activity_init\",    \n",
    "                                act_fn,\n",
    "                                f\"activity_lr_{activity_lr}\",\n",
    "                                f\"{n_infer_iters}_n_infer_iters\"\n",
    "                            )\n",
    "                            os.makedirs(save_dir, exist_ok=True)\n",
    "                    \n",
    "                            # create and initialise model\n",
    "                            d_in, d_out = 1, 1\n",
    "                            L = n_hidden + 1\n",
    "                            model = jpc.make_mlp(\n",
    "                                key=keys[0],\n",
    "                                input_dim=d_in,\n",
    "                                width=WIDTH,\n",
    "                                depth=L,\n",
    "                                output_dim=d_out,\n",
    "                                act_fn=act_fn,\n",
    "                                use_bias=False,\n",
    "                                param_type=param_type\n",
    "                            )\n",
    "                            skip_model = jpc.make_skip_model(L) if use_skips else None\n",
    "                            \n",
    "                            # optimisers\n",
    "                            param_optim = optax.adam(param_lr)\n",
    "                            param_opt_state = param_optim.init(\n",
    "                                (eqx.filter(model, eqx.is_array), skip_model)\n",
    "                            )\n",
    "                            activity_optim = optax.sgd(activity_lr) \n",
    "                                                \n",
    "                            # metrics\n",
    "                            train_losses = np.zeros(N_TRAIN_ITERS+1)\n",
    "                    \n",
    "                            n_test_iters = N_TRAIN_ITERS // TEST_EVERY\n",
    "                            layer_idxs = [0, int(L / 4) - 1, int(L / 2) - 1, int(L * 3 / 4) - 1, L - 1]\n",
    "                            \n",
    "                            train_num_activities = np.zeros(\n",
    "                                (N_TRAIN_ITERS+1, n_infer_iters+1, len(layer_idxs))\n",
    "                            )\n",
    "                            theory_activities_start_end_train = np.zeros((2, len(layer_idxs)))\n",
    "                                                    \n",
    "                            train_num_energies = np.zeros((n_test_iters+1, len(layer_idxs)))\n",
    "                            train_theory_energies = np.zeros_like(train_num_energies)\n",
    "    \n",
    "                            param_spectral_norms = np.zeros((N_TRAIN_ITERS+1, len(layer_idxs)))\n",
    "                            max_min_hess_eigenvals = np.zeros((2, n_test_iters+1))\n",
    "        \n",
    "                            iter_keys = jr.split(keys[-1], N_TRAIN_ITERS)\n",
    "                            for train_iter in range(N_TRAIN_ITERS+1):\n",
    "                                data_key, noise_key, init_key = jr.split(iter_keys[train_iter], 3)\n",
    "                                x = DATA_MEAN + DATA_STD * jr.normal(data_key, (BATCH_SIZE, 1))\n",
    "                                eps = NOISE_STD * jr.normal(noise_key, (BATCH_SIZE, 1))\n",
    "                                y = -x + eps\n",
    "\n",
    "                                # preds\n",
    "                                activities = jpc.init_activities_with_ffwd(\n",
    "                                    model=model,\n",
    "                                    input=x,\n",
    "                                    skip_model=skip_model,\n",
    "                                    param_type=param_type\n",
    "                                )\n",
    "                                preds = activities[-1]\n",
    "                                train_loss = jpc.mse_loss(preds, y)            \n",
    "                                train_losses[train_iter] = train_loss\n",
    "                                if np.isinf(train_loss) or np.isnan(train_loss):\n",
    "                                    break\n",
    "                                \n",
    "                                # initialise activities\n",
    "                                if activity_init == \"random\":\n",
    "                                    activities = jpc.init_activities_from_normal(\n",
    "                                        key=init_key,\n",
    "                                        layer_sizes=[d_in] + [WIDTH]*n_hidden + [d_out],\n",
    "                                        mode=\"supervised\",\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        sigma=1\n",
    "                                    )\n",
    "                                \n",
    "                                elif activity_init == \"theory\":\n",
    "                                    activities = jpc.compute_linear_activity_solution(\n",
    "                                        network=model,\n",
    "                                        x=x,\n",
    "                                        y=y,\n",
    "                                        use_skips=use_skips,\n",
    "                                        param_type=param_type\n",
    "                                    )\n",
    "                                                                \n",
    "                                activity_opt_state = activity_optim.init(activities)\n",
    "                            \n",
    "                                # record metrics at init\n",
    "                                i = 0\n",
    "                                for l, activity in enumerate(activities):\n",
    "                                    if l in layer_idxs:\n",
    "                                        train_num_activities[train_iter, 0, i] = activity.mean()\n",
    "                                        i += 1\n",
    "                            \n",
    "                                if train_iter == 0:\n",
    "                                    theory_activities = jpc.compute_linear_activity_solution(\n",
    "                                        network=model,\n",
    "                                        x=x,\n",
    "                                        y=y,\n",
    "                                        use_skips=use_skips,\n",
    "                                        param_type=param_type,\n",
    "                                    )\n",
    "                                    i = 0\n",
    "                                    for l, activity in enumerate(theory_activities):\n",
    "                                        if l in layer_idxs:\n",
    "                                            theory_activities_start_end_train[train_iter, i] = activity.mean()\n",
    "                                            i += 1\n",
    "    \n",
    "                                    num_energies = jpc.pc_energy_fn(\n",
    "                                        params=(model, skip_model),\n",
    "                                        activities=activities,\n",
    "                                        y=y,\n",
    "                                        x=x,\n",
    "                                        param_type=param_type,\n",
    "                                        record_layers=True\n",
    "                                    )\n",
    "                                    theory_energies = jpc.pc_energy_fn(\n",
    "                                        params=(model, skip_model),\n",
    "                                        activities=theory_activities,\n",
    "                                        y=y,\n",
    "                                        x=x,\n",
    "                                        param_type=param_type,\n",
    "                                        record_layers=True\n",
    "                                    )  \n",
    "                                    train_num_energies[0] = np.array([\n",
    "                                        e for l, e in enumerate(reversed(num_energies)) if l in layer_idxs\n",
    "                                    ])\n",
    "                                    train_theory_energies[0] = np.array([\n",
    "                                        e for l, e in enumerate(reversed(theory_energies)) if l in layer_idxs\n",
    "                                    ])\n",
    "                                                                                                            \n",
    "                                    eigenvals, eigenvecs = compute_hessian_eigens(\n",
    "                                        params=(model, skip_model),\n",
    "                                        activities=tree_map(lambda a: a[[0], :], activities),\n",
    "                                        y=y[[0], :],\n",
    "                                        x=x[[0], :],\n",
    "                                        param_type=param_type\n",
    "                                    )\n",
    "                                    max_min_hess_eigenvals[:, 0] = np.array(\n",
    "                                        [max(eigenvals), min(eigenvals)]\n",
    "                                    )\n",
    "                            \n",
    "                                # inference\n",
    "                                if activity_init != \"theory\":\n",
    "                                    for t in range(n_infer_iters):\n",
    "                                        activity_update_result = jpc.update_activities(\n",
    "                                            params=(model, skip_model),\n",
    "                                            activities=activities,\n",
    "                                            optim=activity_optim,\n",
    "                                            opt_state=activity_opt_state,\n",
    "                                            output=y,\n",
    "                                            input=x,\n",
    "                                            param_type=param_type\n",
    "                                        )\n",
    "                                        activities = activity_update_result[\"activities\"]\n",
    "                                        activity_opt_state = activity_update_result[\"opt_state\"]\n",
    "                                                                                                \n",
    "                                        i = 0\n",
    "                                        for l, act in enumerate(activities):\n",
    "                                            if l in layer_idxs:\n",
    "                                                train_num_activities[train_iter, t+1, i] = jnp.mean(act)\n",
    "                                                i += 1\n",
    "                                else:\n",
    "    \n",
    "                                    i = 0\n",
    "                                    for l, act in enumerate(activities):\n",
    "                                        if l in layer_idxs:\n",
    "                                            train_num_activities[train_iter, 0, i] = jnp.mean(act)\n",
    "                                            i += 1\n",
    "    \n",
    "                                param_spectral_norms[train_iter] = compute_param_spectral_norms(\n",
    "                                    model=model,\n",
    "                                    act_fn=act_fn,\n",
    "                                    layer_idxs=layer_idxs\n",
    "                                )\n",
    "                            \n",
    "                                # update parameters\n",
    "                                param_update_result = jpc.update_params(\n",
    "                                    params=(model, skip_model),\n",
    "                                    activities=activities,\n",
    "                                    optim=param_optim,\n",
    "                                    opt_state=param_opt_state,\n",
    "                                    output=y,\n",
    "                                    input=x,\n",
    "                                    param_type=param_type\n",
    "                                )\n",
    "                                model = param_update_result[\"model\"]\n",
    "                                skip_model = param_update_result[\"skip_model\"]\n",
    "                                param_opt_state = param_update_result[\"opt_state\"]\n",
    "                            \n",
    "                                if train_iter > 0 and train_iter % TEST_EVERY == 0:\n",
    "                                    print(\n",
    "                                        f\"Train loss: {train_loss:.7f} [{train_iter}/{N_TRAIN_ITERS}]\"\n",
    "                                    )\n",
    "                                    test_iter = int(train_iter / TEST_EVERY)\n",
    "                                    theory_activities = jpc.compute_linear_activity_solution(\n",
    "                                        network=model,\n",
    "                                        x=x,\n",
    "                                        y=y,\n",
    "                                        use_skips=use_skips,\n",
    "                                        param_type=param_type\n",
    "                                    )\n",
    "                                    i = 0\n",
    "                                    for l, activity in enumerate(theory_activities):\n",
    "                                        if l in layer_idxs:\n",
    "                                            theory_activities_start_end_train[-1, i] = activity.mean()\n",
    "                                            i += 1\n",
    "    \n",
    "                                    num_energies = jpc.pc_energy_fn(\n",
    "                                        params=(model, skip_model),\n",
    "                                        activities=activities,\n",
    "                                        y=y,\n",
    "                                        x=x,\n",
    "                                        param_type=param_type,\n",
    "                                        record_layers=True\n",
    "                                    )\n",
    "                                    theory_energies = jpc.pc_energy_fn(\n",
    "                                        params=(model, skip_model),\n",
    "                                        activities=theory_activities,\n",
    "                                        y=y,\n",
    "                                        x=x,\n",
    "                                        param_type=param_type,\n",
    "                                        record_layers=True\n",
    "                                    )  \n",
    "                                    train_num_energies[test_iter] = np.array([\n",
    "                                        e for l, e in enumerate(reversed(num_energies)) if l in layer_idxs\n",
    "                                    ])\n",
    "                                    train_theory_energies[test_iter] = np.array([\n",
    "                                        e for l, e in enumerate(reversed(theory_energies)) if l in layer_idxs\n",
    "                                    ])\n",
    "                                    \n",
    "                                    eigenvals, eigenvecs = compute_hessian_eigens(\n",
    "                                        params=(model, skip_model),\n",
    "                                        activities=tree_map(lambda a: a[[0], :], activities),\n",
    "                                        y=y[[0], :],\n",
    "                                        x=x[[0], :],\n",
    "                                        param_type=param_type\n",
    "                                    )\n",
    "                                    max_min_hess_eigenvals[:, test_iter] = np.array(\n",
    "                                        [max(eigenvals), min(eigenvals)]\n",
    "                                    )\n",
    "                             \n",
    "                            # plotting\n",
    "                            plot_2D_data(x, y, preds, f\"{save_dir}/data_samples.pdf\")\n",
    "                            \n",
    "                            plot_loss(\n",
    "                                loss=train_losses,\n",
    "                                yaxis_title=\"Train loss\",\n",
    "                                xaxis_title=\"Iteration\",\n",
    "                                save_path=f\"{save_dir}/train_losses.pdf\",\n",
    "                                mode=\"lines\"\n",
    "                            )\n",
    "                            plot_norms(\n",
    "                                norms=param_spectral_norms,\n",
    "                                norm_type=\"param_spectral\",\n",
    "                                save_path=f\"{save_dir}/param_spectral_norms.pdf\"\n",
    "                            )\n",
    "                            plot_energies(\n",
    "                                energies=train_num_energies.T,\n",
    "                                test_every=TEST_EVERY,\n",
    "                                save_path=f\"{save_dir}/energies.pdf\",\n",
    "                                theory_energies=train_theory_energies.T,\n",
    "                                log=False\n",
    "                            )\n",
    "                            plot_energies(\n",
    "                                energies=train_num_energies.T,\n",
    "                                test_every=TEST_EVERY,\n",
    "                                save_path=f\"{save_dir}/log_energies.pdf\",\n",
    "                                theory_energies=train_theory_energies.T,\n",
    "                                log=True\n",
    "                            )\n",
    "                            plot_max_min_eigenvals(\n",
    "                                max_min_eigenvals=max_min_hess_eigenvals,\n",
    "                                test_every=TEST_EVERY,\n",
    "                                save_path=f\"{save_dir}/max_min_activity_hess_eigenvals.pdf\"\n",
    "                            )\n",
    "                            plot_max_min_eigenvals_2_axes(\n",
    "                                max_min_eigenvals=max_min_hess_eigenvals,\n",
    "                                test_every=TEST_EVERY,\n",
    "                                save_path=f\"{save_dir}/max_min_activity_hess_eigenvals_2_axes.pdf\"\n",
    "                            )\n",
    "    \n",
    "                            # plot activities at start & end of training\n",
    "                            plot_activities(\n",
    "                                activities=train_num_activities[0],\n",
    "                                save_path=f\"{save_dir}/activities_over_inference_at_init.pdf\",\n",
    "                                theory_activities=theory_activities_start_end_train[0],\n",
    "                                log=False\n",
    "                            )                                \n",
    "                            plot_activities(\n",
    "                                activities=train_num_activities[-1],\n",
    "                                save_path=f\"{save_dir}/activities_over_inference_at_last_train_iter.pdf\",\n",
    "                                theory_activities=theory_activities_start_end_train[-1],\n",
    "                                log=False\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training with $z^*$\n",
    "\n",
    "This analyses the inference and learning dynamics of PCNs trained using the analytical inference solution $\\mathbf{z}^* = \\mathbf{H}^{-1}\\mathbf{b}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.tree_util import tree_map\n",
    "\n",
    "from experiments.datasets import get_dataloaders\n",
    "from utils import (\n",
    "    set_seed,    \n",
    "    init_weights,\n",
    "    compute_param_spectral_norms, \n",
    "    compute_hessian_eigens, \n",
    "    spectral_norm,\n",
    "    compute_metric_stats\n",
    ")\n",
    "from plotting import (\n",
    "    plot_loss,\n",
    "    plot_loss_and_accuracy,\n",
    "    plot_n_infer_iters, \n",
    "    plot_norms,\n",
    "    plot_energies,\n",
    "    plot_hessian_eigenvalues_during_training,\n",
    "    plot_max_min_eigenvals,\n",
    "    plot_max_min_eigenvals_2_axes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(params, test_loader, param_type):\n",
    "    model, skip_model = params\n",
    "    avg_test_loss, avg_test_acc = 0, 0\n",
    "    for batch_id, (img_batch, label_batch) in enumerate(test_loader):\n",
    "        img_batch, label_batch = img_batch.numpy(), label_batch.numpy()\n",
    "\n",
    "        test_loss, test_acc = jpc.test_discriminative_pc(\n",
    "            model=model,\n",
    "            output=label_batch,\n",
    "            input=img_batch,\n",
    "            skip_model=skip_model,\n",
    "            param_type=param_type\n",
    "        )\n",
    "        avg_test_loss += test_loss\n",
    "        avg_test_acc += test_acc\n",
    "\n",
    "    return avg_test_loss / len(test_loader), avg_test_acc / len(test_loader)\n",
    "\n",
    "\n",
    "def plot_metric_stats(metric, yaxis_title, test_every, save_path, yaxis_type=\"linear\"):\n",
    "    key = next(iter(metric))\n",
    "    n_train_iters = len(metric[key][0])\n",
    "    train_iters = [t for t in range(n_train_iters)]\n",
    "    \n",
    "    ivs = metric.keys()\n",
    "    colorscale = \"Reds\" if \"loss\" in yaxis_title else \"Blues\"\n",
    "    colors = pc.sample_colorscale(colorscale, len(ivs)+2)[2:]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    for iv, color in zip(ivs, colors):\n",
    "        means, stds = metric[iv][0], metric[iv][1]\n",
    "        y_upper, y_lower = means + stds, means - stds\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=list(train_iters) + list(train_iters[::-1]),\n",
    "                y=list(y_upper) + list(y_lower[::-1]),\n",
    "                fill=\"toself\",\n",
    "                fillcolor=color,\n",
    "                line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "                hoverinfo=\"skip\",\n",
    "                showlegend=False,\n",
    "                opacity=0.3\n",
    "            )\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=train_iters,\n",
    "                y=means,\n",
    "                mode=\"lines\" if \"Train\" in yaxis_title else \"lines+markers\",\n",
    "                line=dict(width=2, color=color),\n",
    "                name=f\"$H={iv}$\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    xtickvals = [0, int(train_iters[-1]/2), train_iters[-1]]\n",
    "    xticktext = xtickvals if (\n",
    "            \"Train\" in yaxis_title\n",
    "    ) else [(t+1) * test_every for t in xtickvals]\n",
    "    fig.update_layout(\n",
    "        height=300,\n",
    "        width=400,\n",
    "        xaxis=dict(\n",
    "            title=\"Training iteration\",\n",
    "            tickvals=xtickvals,\n",
    "            ticktext=xticktext\n",
    "        ),\n",
    "        yaxis=dict(title=yaxis_title, type=yaxis_type),\n",
    "        font=dict(size=16),\n",
    "        margin=dict(r=120)\n",
    "    )\n",
    "    fig.write_image(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theory_save_dir = f\"{SAVE_DIR}/mlps/analytical_inference\"\n",
    "os.makedirs(theory_save_dir, exist_ok=True)\n",
    "\n",
    "# for accurate inversion of the Hessian with wide and deep nets\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "dataset = \"MNIST\"\n",
    "width = 128\n",
    "act_fn = \"linear\"\n",
    "use_skips = True\n",
    "param_optim_id = \"Adam\"\n",
    "activity_optim_id = \"GD\"\n",
    "activity_lr = 1\n",
    "batch_size = 64\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 100\n",
    "n_seeds = 3\n",
    "\n",
    "sigma = 1\n",
    "\n",
    "PARAM_TYPES = [\"mupc\"]  #sp\n",
    "N_HIDDENS = [8, 16, 32]\n",
    "for param_type in PARAM_TYPES:\n",
    "    for n_hidden in N_HIDDENS:\n",
    "        for seed in range(n_seeds):\n",
    "            print(\n",
    "                f\"\\nStarting experiment with {param_type}, H = {n_hidden}, seed {seed}\\n\"\n",
    "            )\n",
    "            save_dir = os.path.join(\n",
    "                theory_save_dir,\n",
    "                param_type,\n",
    "                f\"{n_hidden}_n_hidden\",\n",
    "                str(seed)\n",
    "            )\n",
    "            set_seed(seed)\n",
    "            key = jax.random.PRNGKey(seed)\n",
    "            keys = jax.random.split(key, 2)\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "            # create and initialise model\n",
    "            d_in, d_out = 784, 10\n",
    "            L = n_hidden + 1\n",
    "            model = jpc.make_mlp(\n",
    "                key=keys[0],\n",
    "                input_dim=d_in,\n",
    "                width=width,\n",
    "                depth=L,\n",
    "                output_dim=d_out,\n",
    "                act_fn=act_fn,\n",
    "                use_bias=False,\n",
    "                param_type=param_type\n",
    "            )\n",
    "            skip_model = jpc.make_skip_model(L) if use_skips else None\n",
    "            \n",
    "            # optimisers\n",
    "            param_lr = 1e-3 if param_type == \"sp\" else 1e-1\n",
    "            if param_optim_id == \"SGD\":\n",
    "                param_optim = optax.sgd(param_lr)\n",
    "            elif param_optim_id == \"Adam\":\n",
    "                param_optim = optax.adam(param_lr)\n",
    "            \n",
    "            param_opt_state = param_optim.init(\n",
    "                (eqx.filter(model, eqx.is_array), skip_model)\n",
    "            )\n",
    "            \n",
    "            activity_optim = optax.sgd(activity_lr) if (\n",
    "                    activity_optim_id == \"GD\"\n",
    "            ) else optax.adam(activity_lr)\n",
    "            \n",
    "            # data\n",
    "            train_loader, test_loader = get_dataloaders(dataset, batch_size)\n",
    "            \n",
    "            # metrics\n",
    "            train_losses = []\n",
    "            test_losses, test_accs = [], []\n",
    "    \n",
    "            n_train_iters = len(train_loader.dataset) // batch_size * max_epochs\n",
    "            n_test_iters = n_train_iters // test_every * max_epochs\n",
    "            layer_idxs = [0, int(L / 4) - 1, int(L / 2) - 1, int(L * 3 / 4) - 1, L - 1]\n",
    "        \n",
    "            activity_l2_norms = np.zeros((n_train_iters, len(layer_idxs)))\n",
    "            \n",
    "            param_spectral_norms = np.zeros((n_train_iters+1, len(layer_idxs)))    \n",
    "            hessian_eigenvals = np.zeros((n_test_iters + 1, width * n_hidden))\n",
    "            max_min_hess_eigenvals = np.zeros((2, n_test_iters + 1))\n",
    "            \n",
    "            train_num_energies = np.zeros((n_test_iters + 1, len(layer_idxs)))\n",
    "            \n",
    "            global_batch_id = 0\n",
    "            for train_iter, (img_batch, label_batch) in enumerate(train_loader):\n",
    "                img_batch, label_batch = img_batch.numpy(), label_batch.numpy()\n",
    "        \n",
    "                # compute theory activities\n",
    "                activities = jpc.compute_linear_activity_solution(\n",
    "                    network=model,\n",
    "                    x=img_batch,\n",
    "                    y=label_batch,\n",
    "                    use_skips=use_skips,\n",
    "                    param_type=param_type,\n",
    "                    activity_decay=activity_decay\n",
    "                )\n",
    "                train_loss = jpc.mse_loss(activities[-1], label_batch)\n",
    "        \n",
    "                i = 0\n",
    "                for l, act in enumerate(activities):\n",
    "                    if l in layer_idxs:\n",
    "                        activity_l2_norms[global_batch_id, i] = np.array(\n",
    "                            jnp.linalg.norm(act, axis=1, ord=2).mean()\n",
    "                        )\n",
    "                        i += 1\n",
    "                \n",
    "                if global_batch_id == 0:\n",
    "                    energies = jpc.pc_energy_fn(\n",
    "                        params=(model, skip_model),\n",
    "                        activities=activities,\n",
    "                        y=label_batch,\n",
    "                        x=img_batch,\n",
    "                        param_type=param_type,\n",
    "                        activity_decay=activity_decay,\n",
    "                        weight_decay=weight_decay,\n",
    "                        spectral_penalty=spectral_penalty,\n",
    "                        record_layers=True\n",
    "                    )\n",
    "                    train_num_energies[0] = np.array([\n",
    "                            e for l, e in enumerate(reversed(energies)) if l in layer_idxs\n",
    "                    ])\n",
    "            \n",
    "                    param_spectral_norms[0] = compute_param_spectral_norms(\n",
    "                        model=model,\n",
    "                        act_fn=act_fn,\n",
    "                        layer_idxs=layer_idxs\n",
    "                    )\n",
    "                    eigenvals, eigenvecs = compute_hessian_eigens(\n",
    "                        params=(model, skip_model),\n",
    "                        activities=tree_map(lambda a: a[[0], :], activities),\n",
    "                        y=label_batch[[0], :],\n",
    "                        x=img_batch[[0], :],\n",
    "                        param_type=param_type,\n",
    "                        activity_decay=activity_decay,\n",
    "                        weight_decay=weight_decay,\n",
    "                        spectral_penalty=spectral_penalty\n",
    "                    )\n",
    "                    hessian_eigenvals[0] = eigenvals\n",
    "                    max_min_hess_eigenvals[:, 0] = np.array(\n",
    "                        [max(eigenvals), min(eigenvals)]\n",
    "                    )\n",
    "        \n",
    "                # update parameters\n",
    "                param_update_result = jpc.update_params(\n",
    "                    params=(model, skip_model),\n",
    "                    activities=activities,\n",
    "                    optim=param_optim,\n",
    "                    opt_state=param_opt_state,\n",
    "                    output=label_batch,\n",
    "                    input=img_batch,\n",
    "                    param_type=param_type,\n",
    "                    activity_decay=activity_decay,\n",
    "                    weight_decay=weight_decay,\n",
    "                    spectral_penalty=spectral_penalty\n",
    "                )\n",
    "                model = param_update_result[\"model\"]\n",
    "                skip_model = param_update_result[\"skip_model\"]\n",
    "                param_opt_state = param_update_result[\"opt_state\"]\n",
    "            \n",
    "                param_spectral_norms[global_batch_id+1] = compute_param_spectral_norms(\n",
    "                    model=model,\n",
    "                    act_fn=act_fn,\n",
    "                    layer_idxs=layer_idxs\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                global_batch_id += 1\n",
    "            \n",
    "                if global_batch_id % test_every == 0:\n",
    "                    print(\n",
    "                        f\"Train loss: {train_loss:.7f} [{train_iter * len(img_batch)}/{len(train_loader.dataset)}]\"\n",
    "                    )\n",
    "                    avg_test_loss, avg_test_acc = evaluate(\n",
    "                        params=(model, skip_model),\n",
    "                        test_loader=test_loader,\n",
    "                        param_type=param_type\n",
    "                    )\n",
    "                    test_losses.append(avg_test_loss)\n",
    "                    test_accs.append(avg_test_acc)\n",
    "                    print(f\"Avg test accuracy: {avg_test_acc:.4f}\\n\")\n",
    "            \n",
    "                    test_iter = int(global_batch_id / test_every)\n",
    "                    eigenvals, eigenvecs = compute_hessian_eigens(\n",
    "                        params=(model, skip_model),\n",
    "                        activities=tree_map(lambda a: a[[0], :], activities),\n",
    "                        y=label_batch[[0], :],\n",
    "                        x=img_batch[[0], :],\n",
    "                        param_type=param_type,\n",
    "                        activity_decay=activity_decay,\n",
    "                        weight_decay=weight_decay,\n",
    "                        spectral_penalty=spectral_penalty\n",
    "                    )\n",
    "                    hessian_eigenvals[test_iter] = eigenvals\n",
    "                    max_min_hess_eigenvals[:, test_iter] = np.array(\n",
    "                        [max(eigenvals), min(eigenvals)]\n",
    "                    )\n",
    "                    energies = jpc.pc_energy_fn(\n",
    "                        params=(model, skip_model),\n",
    "                        activities=activities,\n",
    "                        y=label_batch,\n",
    "                        x=img_batch,\n",
    "                        param_type=param_type,\n",
    "                        activity_decay=activity_decay,\n",
    "                        weight_decay=weight_decay,\n",
    "                        spectral_penalty=spectral_penalty,\n",
    "                        record_layers=True\n",
    "                    )\n",
    "                    train_num_energies[test_iter] = np.array([\n",
    "                            e for l, e in enumerate(reversed(energies)) if l in layer_idxs\n",
    "                        ])\n",
    "    \n",
    "            np.save(f\"{save_dir}/train_losses.npy\", train_losses)\n",
    "            np.save(f\"{save_dir}/test_losses.npy\", test_losses)\n",
    "            np.save(f\"{save_dir}/test_accs.npy\", test_accs)\n",
    "             \n",
    "            # plotting\n",
    "            plot_loss(\n",
    "                loss=train_losses,\n",
    "                yaxis_title=\"Train loss\",\n",
    "                xaxis_title=\"Iteration\",\n",
    "                save_path=f\"{save_dir}/train_losses.pdf\"\n",
    "            )\n",
    "            plot_loss_and_accuracy(\n",
    "                loss=test_losses,\n",
    "                accuracy=test_accs,\n",
    "                mode=\"test\",\n",
    "                xaxis_title=\"Training iteration\",\n",
    "                save_path=f\"{save_dir}/test_losses_and_accs.pdf\",\n",
    "                test_every=test_every\n",
    "            )\n",
    "            plot_norms(\n",
    "                norms=param_spectral_norms,\n",
    "                norm_type=\"param_spectral\",\n",
    "                save_path=f\"{save_dir}/param_spectral_norms.pdf\"\n",
    "            )\n",
    "            plot_energies(\n",
    "                energies=train_num_energies.T,\n",
    "                test_every=test_every,\n",
    "                save_path=f\"{save_dir}/energies.pdf\",\n",
    "                log=False\n",
    "            )\n",
    "            plot_energies(\n",
    "                energies=train_num_energies.T,\n",
    "                test_every=test_every,\n",
    "                save_path=f\"{save_dir}/log_energies.pdf\",\n",
    "                log=True\n",
    "            )\n",
    "            plot_hessian_eigenvalues_during_training(\n",
    "                eigenvals=[e for i, e in enumerate(hessian_eigenvals) if i % 2 == 0],\n",
    "                test_every=200,\n",
    "                save_path=f\"{save_dir}/hessian_eigenvals.pdf\"\n",
    "            )\n",
    "            plot_max_min_eigenvals(\n",
    "                max_min_eigenvals=max_min_hess_eigenvals,\n",
    "                test_every=test_every,\n",
    "                save_path=f\"{save_dir}/max_min_eigenvals.pdf\"\n",
    "            )\n",
    "            plot_max_min_eigenvals_2_axes(\n",
    "                max_min_eigenvals=max_min_hess_eigenvals,\n",
    "                test_every=test_every,\n",
    "                save_path=f\"{save_dir}/max_min_eigenvals_2_axes.pdf\"\n",
    "            )\n",
    "            plot_norms(\n",
    "                norms=np.array([activity_l2_norms[0]] * 2),\n",
    "                norm_type=\"activity\",\n",
    "                save_path=f\"{save_dir}/theory_activity_l2_norms_at_init.pdf\",\n",
    "                theory_norms=activity_l2_norms[0],\n",
    "                showticklabels=False\n",
    "            )\n",
    "            plot_norms(\n",
    "                norms=np.array([activity_l2_norms[-1]] * 2),\n",
    "                norm_type=\"activity\",\n",
    "                save_path=f\"{save_dir}/theory_activity_l2_norms_last_train_iter.pdf\",\n",
    "                theory_norms=activity_l2_norms[-1],\n",
    "                showticklabels=False\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ plot results ############\n",
    "PARAM_TYPES = [\"sp\", \"mupc\"]\n",
    "N_HIDDENS = [8, 16, 32]\n",
    "n_seeds = 3\n",
    "test_every = 100\n",
    "\n",
    "train_losses_per_H = {}\n",
    "test_losses_per_H = {}\n",
    "test_accs_per_H = {}\n",
    "for param_type in PARAM_TYPES:\n",
    "    for n_hidden in N_HIDDENS:\n",
    "            \n",
    "        train_losses_all_seeds = np.zeros((n_seeds, 937))\n",
    "        test_losses_all_seeds = np.zeros((n_seeds, 9))\n",
    "        test_accs_all_seeds = np.zeros_like(test_losses_all_seeds)\n",
    "        for seed in range(n_seeds):\n",
    "            save_dir = os.path.join(\n",
    "                theory_save_dir,\n",
    "                param_type,\n",
    "                f\"{n_hidden}_n_hidden\",\n",
    "                str(seed)\n",
    "            )\n",
    "            train_losses = np.load(f\"{save_dir}/train_losses.npy\")\n",
    "            test_losses = np.load(f\"{save_dir}/test_losses.npy\")\n",
    "            test_accs = np.load(f\"{save_dir}/test_accs.npy\")\n",
    "\n",
    "            train_losses_all_seeds[seed] = train_losses\n",
    "            test_losses_all_seeds[seed] = test_losses\n",
    "            test_accs_all_seeds[seed] = test_accs\n",
    "    \n",
    "        train_losses_means, train_losses_stds = compute_metric_stats(train_losses_all_seeds)\n",
    "        test_losses_means, test_losses_stds = compute_metric_stats(test_losses_all_seeds)\n",
    "        test_acc_means, test_acc_stds = compute_metric_stats(test_accs_all_seeds)\n",
    "    \n",
    "        train_losses_per_H[n_hidden] = (train_losses_means, train_losses_stds)\n",
    "        test_losses_per_H[n_hidden] = (test_losses_means, test_losses_stds)\n",
    "        test_accs_per_H[n_hidden] = (test_acc_means, test_acc_stds)\n",
    "    \n",
    "    plot_metric_stats(\n",
    "        metric=train_losses_per_H, \n",
    "        yaxis_title=\"Train loss\", \n",
    "        test_every=test_every,\n",
    "        save_path=f\"{theory_save_dir}/{param_type}_train_losses.pdf\",\n",
    "        yaxis_type=\"log\" if param_type == \"sp\" else \"linear\"\n",
    "    )\n",
    "    plot_metric_stats(\n",
    "        metric=test_losses_per_H, \n",
    "        yaxis_title=\"Test loss\",\n",
    "        test_every=test_every,\n",
    "        save_path=f\"{theory_save_dir}/{param_type}_test_losses.pdf\",\n",
    "        yaxis_type=\"log\" if param_type == \"sp\" else \"linear\"\n",
    "    )\n",
    "    plot_metric_stats(\n",
    "        metric=test_accs_per_H, \n",
    "        yaxis_title=\"Test accuracy (%)\",\n",
    "        test_every=test_every,\n",
    "        save_path=f\"{theory_save_dir}/{param_type}_test_accs.pdf\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
