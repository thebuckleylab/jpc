{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error-reparameterised Predictive Coding (ePC)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/thebuckleylab/jpc/blob/main/examples/epc.ipynb)\n",
    "\n",
    "This notebook demonstrates how to train PC networks with [**ePC**](https://openreview.net/forum?id=lQhBWz59qW), a reparameterisation of PC that can allow for faster convergence of the inference dynamics (see [Goemaere et al., 2025](https://openreview.net/forum?id=lQhBWz59qW))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install torch==2.3.1\n",
    "!pip install torchvision==0.18.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jpc\n",
    "\n",
    "import numpy as np\n",
    "import jax.random as jr\n",
    "import equinox as eqx\n",
    "import optax\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')  # ignore warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "We define some global parameters, including the network architecture, learning rate, batch size, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 128\n",
    "DEPTH = 10\n",
    "ACT_FN = \"relu\"\n",
    "\n",
    "STATE_LR = 5e-1  # for either activities (PC) or errors (ePC)\n",
    "PARAM_LR = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "TEST_EVERY = 100\n",
    "N_TRAIN_ITERS = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Some utils to fetch MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_loaders(batch_size):\n",
    "    train_data = MNIST(train=True, normalise=True)\n",
    "    test_data = MNIST(train=False, normalise=True)\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        dataset=test_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "class MNIST(datasets.MNIST):\n",
    "    def __init__(self, train, normalise=True, save_dir=\"data\"):\n",
    "        if normalise:\n",
    "            transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(\n",
    "                        mean=(0.1307), std=(0.3081)\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            transform = transforms.Compose([transforms.ToTensor()])\n",
    "        super().__init__(save_dir, download=True, train=train, transform=transform)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, label = super().__getitem__(index)\n",
    "        img = torch.flatten(img)\n",
    "        label = one_hot(label)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "def one_hot(labels, n_classes=10):\n",
    "    arr = torch.eye(n_classes)\n",
    "    return arr[labels]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    avg_test_acc = 0\n",
    "    for _, (img_batch, label_batch) in enumerate(test_loader):\n",
    "        img_batch, label_batch = img_batch.numpy(), label_batch.numpy()\n",
    "\n",
    "        _, test_acc = jpc.test_discriminative_pc(\n",
    "            model=model,\n",
    "            input=img_batch,\n",
    "            output=label_batch\n",
    "        )\n",
    "        avg_test_acc += test_acc\n",
    "\n",
    "    return avg_test_acc / len(test_loader)\n",
    "\n",
    "\n",
    "def train(\n",
    "      algo,\n",
    "      width,\n",
    "      depth,\n",
    "      act_fn,\n",
    "      state_lr,  \n",
    "      param_lr,\n",
    "      batch_size,\n",
    "      test_every,\n",
    "      n_train_iters\n",
    "):  \n",
    "    key = jr.PRNGKey(5482)\n",
    "    model = jpc.make_mlp(\n",
    "        key,\n",
    "        input_dim=784,\n",
    "        width=width,\n",
    "        depth=depth,\n",
    "        output_dim=10,\n",
    "        act_fn=act_fn,\n",
    "        use_bias=True\n",
    "    )\n",
    "    layer_sizes = [784] + [width] * (depth-1) + [10]\n",
    "    \n",
    "    if algo == \"pc\":\n",
    "        activity_optim = optax.sgd(state_lr)\n",
    "    elif algo == \"epc\":\n",
    "        error_optim = optax.sgd(state_lr)\n",
    "\n",
    "    param_optim = optax.adam(param_lr)\n",
    "    param_opt_state = param_optim.init(\n",
    "        (eqx.filter(model, eqx.is_array), None)\n",
    "    )\n",
    "    train_loader, test_loader = get_mnist_loaders(batch_size)\n",
    "\n",
    "    for iter, (img_batch, label_batch) in enumerate(train_loader):\n",
    "        img_batch, label_batch = img_batch.numpy(), label_batch.numpy()\n",
    "\n",
    "        # initialise activities or errors\n",
    "        activities = jpc.init_activities_with_ffwd(\n",
    "            model=model,\n",
    "            input=img_batch\n",
    "        )\n",
    "        train_loss = jpc.mse_loss(activities[-1], label_batch)\n",
    "\n",
    "        if algo == \"pc\":\n",
    "            activity_opt_state = activity_optim.init(activities)\n",
    "        \n",
    "        elif algo == \"epc\":\n",
    "            errors = jpc.init_epc_errors(\n",
    "                layer_sizes=layer_sizes,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "            error_opt_state = error_optim.init(errors)\n",
    "\n",
    "        # inference\n",
    "        for _ in range(len(model)):\n",
    "            if algo == \"pc\":\n",
    "                activity_update_result = jpc.update_pc_activities(\n",
    "                    params=(model, None),\n",
    "                    activities=activities,\n",
    "                    optim=activity_optim,\n",
    "                    opt_state=activity_opt_state,\n",
    "                    output=label_batch,\n",
    "                    input=img_batch\n",
    "                )\n",
    "                activities = activity_update_result[\"activities\"]\n",
    "                activity_opt_state = activity_update_result[\"opt_state\"]\n",
    "            \n",
    "            elif algo == \"epc\":\n",
    "                error_update_result = jpc.update_epc_errors(\n",
    "                    params=(model, None),\n",
    "                    errors=errors,\n",
    "                    optim=error_optim,\n",
    "                    opt_state=error_opt_state,\n",
    "                    output=label_batch,\n",
    "                    input=img_batch\n",
    "                )\n",
    "                errors = error_update_result[\"errors\"]\n",
    "                error_opt_state = error_update_result[\"opt_state\"]\n",
    "\n",
    "        # learning\n",
    "        if algo == \"pc\":\n",
    "            param_update_result = jpc.update_pc_params(\n",
    "                params=(model, None),\n",
    "                activities=activities,\n",
    "                optim=param_optim,\n",
    "                opt_state=param_opt_state,\n",
    "                output=label_batch,\n",
    "                input=img_batch\n",
    "            )\n",
    "        elif algo == \"epc\":\n",
    "            param_update_result = jpc.update_epc_params(\n",
    "                params=(model, None),\n",
    "                errors=errors,\n",
    "                optim=param_optim,\n",
    "                opt_state=param_opt_state,\n",
    "                output=label_batch,\n",
    "                input=img_batch\n",
    "            )\n",
    "        \n",
    "        model = param_update_result[\"model\"]\n",
    "        param_opt_state = param_update_result[\"opt_state\"]\n",
    "\n",
    "        if np.isinf(train_loss) or np.isnan(train_loss):\n",
    "            print(\n",
    "                f\"Stopping training because of divergence, train loss={train_loss}\"\n",
    "            )\n",
    "            break\n",
    "    \n",
    "        if ((iter+1) % test_every) == 0:\n",
    "            avg_test_acc = evaluate(model=model, test_loader=test_loader)\n",
    "            print(\n",
    "                f\"Train iter {iter+1}, train loss={train_loss:4f}, \"\n",
    "                f\"avg test accuracy={avg_test_acc:4f}\"\n",
    "            )\n",
    "            if (iter+1) >= n_train_iters:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script below should take ~30s to run on a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 100, train loss=0.024090, avg test accuracy=70.933495\n",
      "Train iter 200, train loss=0.007202, avg test accuracy=90.014023\n",
      "Train iter 300, train loss=0.008470, avg test accuracy=93.249199\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    algo=\"epc\",\n",
    "    width=WIDTH,\n",
    "    depth=DEPTH,\n",
    "    act_fn=ACT_FN,\n",
    "    state_lr=STATE_LR,\n",
    "    param_lr=PARAM_LR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    test_every=TEST_EVERY,\n",
    "    n_train_iters=N_TRAIN_ITERS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, try to change to standard pc with `algo = \"pc\"`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
